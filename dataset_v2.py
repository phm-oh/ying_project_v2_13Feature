# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def generate_simplified_student_dataset(n_samples=1789, base_accuracy=0.80, target_after_selection=0.87, seed=42):
    """
    à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ - à¹‚à¸Ÿà¸à¸±à¸ªà¸—à¸µà¹ˆ academic performance
    
    à¸«à¸¥à¸±à¸à¸à¸²à¸£: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¹à¸œà¸™à¸à¸„à¸§à¸£à¸‚à¸¶à¹‰à¸™à¸­à¸¢à¸¹à¹ˆà¸à¸±à¸š academic performance à¹à¸¥à¸° interests à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸
    à¸¥à¸š lifestyle factors à¹à¸¥à¸° validation features à¸­à¸­à¸à¹€à¸à¸·à¹ˆà¸­à¸¥à¸”à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™
    """
    
    np.random.seed(seed)
    departments = ['à¸šà¸±à¸à¸Šà¸µ', 'à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨', 'à¸­à¸²à¸«à¸²à¸£']
    
    # ========== CORE FEATURES (à¸„à¸°à¹à¸™à¸™à¸ˆà¸²à¸à¹à¸šà¸šà¸—à¸”à¸ªà¸­à¸š + à¸—à¸±à¸à¸©à¸°à¸«à¸¥à¸±à¸) ==========
    # à¸„à¸°à¹à¸™à¸™à¸§à¸´à¸Šà¸²à¸«à¸¥à¸±à¸ (1-100)
    math_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    computer_score = np.round(np.random.uniform(30, 100, n_samples), 1)  
    language_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    science_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    art_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    
    # à¸—à¸±à¸à¸©à¸°à¸«à¸¥à¸±à¸ (1-10 scale)
    logical_thinking = np.round(np.random.uniform(3, 10, n_samples), 1)
    creativity_skill = np.round(np.random.uniform(3, 10, n_samples), 1)
    problem_solving = np.round(np.random.uniform(3, 10, n_samples), 1)
    
    # à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸«à¸¥à¸±à¸ (1-10 scale)
    interest_numbers = np.round(np.random.uniform(1, 10, n_samples), 1)
    interest_technology = np.round(np.random.uniform(1, 10, n_samples), 1)
    interest_cooking = np.round(np.random.uniform(1, 10, n_samples), 1)
    
    # ========== DEMOGRAPHIC FEATURES (à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹ˆà¸§à¹„à¸› - à¸ˆà¸³à¸à¸±à¸”à¹€à¸‰à¸à¸²à¸°à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™) ==========
    np.random.seed(seed * 3 + 1000)  # à¹ƒà¸Šà¹‰ seed à¸•à¹ˆà¸²à¸‡à¸­à¸­à¸à¹„à¸›
    age = np.random.randint(16, 20, n_samples)
    gender = np.random.choice([0, 1], n_samples)  # 0: à¸Šà¸²à¸¢, 1: à¸«à¸à¸´à¸‡
    
    # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame
    data = {
        # === CORE FEATURES ===
        'à¸„à¸°à¹à¸™à¸™à¸„à¸“à¸´à¸•à¸¨à¸²à¸ªà¸•à¸£à¹Œ': math_score,
        'à¸„à¸°à¹à¸™à¸™à¸„à¸­à¸¡à¸à¸´à¸§à¹€à¸•à¸­à¸£à¹Œ': computer_score,
        'à¸„à¸°à¹à¸™à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢': language_score,
        'à¸„à¸°à¹à¸™à¸™à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ': science_score,
        'à¸„à¸°à¹à¸™à¸™à¸¨à¸´à¸¥à¸›à¸°': art_score,
        'à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¸„à¸´à¸”à¹€à¸Šà¸´à¸‡à¸•à¸£à¸£à¸à¸°': logical_thinking,
        'à¸—à¸±à¸à¸©à¸°à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ': creativity_skill,
        'à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²': problem_solving,
        'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚': interest_numbers,
        'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ': interest_technology,
        'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸—à¸³à¸­à¸²à¸«à¸²à¸£': interest_cooking,
        
        # === DEMOGRAPHIC FEATURES ===
        'à¸­à¸²à¸¢à¸¸': age,
        'à¹€à¸à¸¨': gender
    }
    
    df = pd.DataFrame(data)
    
    # ========== à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸°à¹à¸™à¸™à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ (à¹ƒà¸Šà¹‰à¹€à¸‰à¸à¸²à¸° CORE FEATURES) ==========
    
    # 1. à¹à¸œà¸™à¸à¸šà¸±à¸à¸Šà¸µ - à¹€à¸™à¹‰à¸™à¸„à¸“à¸´à¸• + à¸•à¸£à¸£à¸à¸° + à¸•à¸±à¸§à¹€à¸¥à¸‚
    accounting_score = (
        2.0 * df['à¸„à¸°à¹à¸™à¸™à¸„à¸“à¸´à¸•à¸¨à¸²à¸ªà¸•à¸£à¹Œ'] +
        1.8 * df['à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¸„à¸´à¸”à¹€à¸Šà¸´à¸‡à¸•à¸£à¸£à¸à¸°'] +
        1.5 * df['à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚'] +
        0.8 * df['à¸„à¸°à¹à¸™à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢']
    )
    
    # 2. à¹à¸œà¸™à¸à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨ - à¹€à¸™à¹‰à¸™à¸„à¸­à¸¡à¸à¸´à¸§à¹€à¸•à¸­à¸£à¹Œ + à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ + à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²  
    it_score = (
        2.0 * df['à¸„à¸°à¹à¸™à¸™à¸„à¸­à¸¡à¸à¸´à¸§à¹€à¸•à¸­à¸£à¹Œ'] +
        1.8 * df['à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ'] +
        1.5 * df['à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²'] +
        1.2 * df['à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¸„à¸´à¸”à¹€à¸Šà¸´à¸‡à¸•à¸£à¸£à¸à¸°'] +
        0.8 * df['à¸„à¸°à¹à¸™à¸™à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ']
    )
    
    # 3. à¹à¸œà¸™à¸à¸­à¸²à¸«à¸²à¸£ - à¹€à¸™à¹‰à¸™à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ + à¸à¸²à¸£à¸—à¸³à¸­à¸²à¸«à¸²à¸£ + à¸¨à¸´à¸¥à¸›à¸°
    food_score = (
        2.0 * df['à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸—à¸³à¸­à¸²à¸«à¸²à¸£'] +
        1.8 * df['à¸—à¸±à¸à¸©à¸°à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ'] +
        1.5 * df['à¸„à¸°à¹à¸™à¸™à¸¨à¸´à¸¥à¸›à¸°'] +
        1.0 * df['à¸„à¸°à¹à¸™à¸™à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ'] +
        0.8 * df['à¸„à¸°à¹à¸™à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢']
    )
    
    # à¹€à¸à¸´à¹ˆà¸¡ noise à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸ªà¸¡à¸ˆà¸£à¸´à¸‡
    noise_strength = (1.0 - base_accuracy) * 8
    accounting_score += np.random.normal(0, noise_strength, n_samples)
    it_score += np.random.normal(0, noise_strength, n_samples)
    food_score += np.random.normal(0, noise_strength, n_samples)
    
    # à¸à¸³à¸«à¸™à¸”à¹à¸œà¸™à¸à¸•à¸²à¸¡à¸„à¸°à¹à¸™à¸™à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
    scores = pd.DataFrame({
        'à¸šà¸±à¸à¸Šà¸µ': accounting_score,
        'à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨': it_score,
        'à¸­à¸²à¸«à¸²à¸£': food_score
    })
    
    department = scores.idxmax(axis=1)
    df['à¹à¸œà¸™à¸'] = department
    
    # ========== à¸—à¸”à¸ªà¸­à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ ==========
    
    # à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡ features à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸š
    core_features = [
        'à¸„à¸°à¹à¸™à¸™à¸„à¸“à¸´à¸•à¸¨à¸²à¸ªà¸•à¸£à¹Œ', 'à¸„à¸°à¹à¸™à¸™à¸„à¸­à¸¡à¸à¸´à¸§à¹€à¸•à¸­à¸£à¹Œ', 'à¸„à¸°à¹à¸™à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢', 'à¸„à¸°à¹à¸™à¸™à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œ', 'à¸„à¸°à¹à¸™à¸™à¸¨à¸´à¸¥à¸›à¸°',
        'à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¸„à¸´à¸”à¹€à¸Šà¸´à¸‡à¸•à¸£à¸£à¸à¸°', 'à¸—à¸±à¸à¸©à¸°à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ', 'à¸—à¸±à¸à¸©à¸°à¸à¸²à¸£à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²',
        'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚', 'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ', 'à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆà¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸—à¸³à¸­à¸²à¸«à¸²à¸£'
    ]
    
    demographic_features = [
        'à¸­à¸²à¸¢à¸¸', 'à¹€à¸à¸¨'
    ]
    
    X = df.drop('à¹à¸œà¸™à¸', axis=1)
    y = df['à¹à¸œà¸™à¸']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)
    
    # à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š features à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
    model_all = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=seed)
    model_all.fit(X_train, y_train)
    y_pred_all = model_all.predict(X_test)
    accuracy_all = accuracy_score(y_test, y_pred_all)
    
    # à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š core features à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
    X_core = df[core_features]
    X_train_core, X_test_core, _, _ = train_test_split(X_core, y, test_size=0.3, random_state=seed, stratify=y)
    
    model_core = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=seed)
    model_core.fit(X_train_core, y_train)
    y_pred_core = model_core.predict(X_test_core)
    accuracy_core = accuracy_score(y_test, y_pred_core)
    
    # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
    print(f"à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™ {n_samples} à¸„à¸™ (à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢)")
    print(f"à¸à¸²à¸£à¹à¸¢à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:")
    print(f"â€¢ Core Features: {len(core_features)} features - à¸„à¸°à¹à¸™à¸™, à¸—à¸±à¸à¸©à¸°, à¸„à¸§à¸²à¸¡à¸ªà¸™à¹ƒà¸ˆ")  
    print(f"â€¢ Demographic Features: {len(demographic_features)} features - à¸­à¸²à¸¢à¸¸, à¹€à¸à¸¨")
    print(f"à¸ˆà¸³à¸™à¸§à¸™à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹à¸œà¸™à¸:")
    print(df['à¹à¸œà¸™à¸'].value_counts())
    
    print(f"\nğŸ“Š à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š:")
    print(f"ğŸ” à¹ƒà¸Šà¹‰ Features à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” ({len(X.columns)} features): {accuracy_all:.3f}")
    print(f"ğŸ¯ à¹ƒà¸Šà¹‰ Core Features à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ ({len(core_features)} features): {accuracy_core:.3f}")
    print(f"âœ¨ à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡: {accuracy_core - accuracy_all:.3f}")
    
    # à¹à¸ªà¸”à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡ features
    feature_imp_all = None
    feature_imp_core = None
    
    if hasattr(model_all, 'feature_importances_'):
        # à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸ à¸— features
        feature_types = []
        for feature in X.columns:
            if feature in core_features:
                feature_types.append('Core')
            elif feature in demographic_features:
                feature_types.append('Demographic')  
            else:
                feature_types.append('Additional')
        
        feature_imp_all = pd.DataFrame({
            'Feature': X.columns,
            'Importance': model_all.feature_importances_,
            'Type': feature_types
        }).sort_values('Importance', ascending=False)
        
        feature_imp_core = pd.DataFrame({
            'Feature': core_features,
            'Importance': model_core.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        print("\nğŸ† Top 10 Most Important Features (Random Forest Analysis):")
        print(feature_imp_all.head(10)[['Feature', 'Importance', 'Type']])
        
        print("\nğŸ¯ Core Features Ranking:")
        print(feature_imp_core.head(11))
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Demographic Features à¸¢à¸±à¸‡à¸•à¸´à¸” Top 10 à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        top_10 = feature_imp_all.head(10)
        demographic_in_top10 = top_10[top_10['Type'] == 'Demographic']
        if len(demographic_in_top10) > 0:
            print(f"\nğŸ“ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸à¸š Demographic Features à¹ƒà¸™ Top 10:")
            print(demographic_in_top10[['Feature', 'Importance']])
        else:
            print(f"\nâœ… à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸•à¸²à¸¡à¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡: Core Features à¸„à¸£à¸­à¸‡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸«à¸¥à¸±à¸")
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡ target
        print(f"\nğŸ” à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡à¹à¸œà¸™à¸à¹€à¸£à¸µà¸¢à¸™:")
        dept_dist = df['à¹à¸œà¸™à¸'].value_counts(normalize=True) * 100
        for dept, pct in dept_dist.items():
            print(f"   {dept}: {pct:.1f}%")
    
    return df, accuracy_all, accuracy_core, feature_imp_all, feature_imp_core, core_features, demographic_features

if __name__ == "__main__":
    print("=== à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ ===")
    
    df, acc_all, acc_core, feat_imp_all, feat_imp_core, core_feat, demo_feat = generate_simplified_student_dataset()
    
    # à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸Ÿà¸¥à¹Œ
    df.to_csv('student_realistic_data.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸Ÿà¸¥à¹Œ student_realistic_data.csv à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§")
    print(f"ğŸ“ Total Features: {len(df.columns)-1}")
    print(f"ğŸ“Š Total Rows: {len(df)}")
    print(f"\nğŸ¯ Dataset à¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ à¹‚à¸Ÿà¸à¸±à¸ªà¸—à¸µà¹ˆ academic performance")
    print(f"âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸š Machine Learning Pipeline")