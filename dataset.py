# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def generate_realistic_student_dataset(n_samples=2000, base_accuracy=0.80, target_after_selection=0.87, seed=42):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á - Features ‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏Å‡πá‡∏ö
    """
    
    np.random.seed(seed)
    departments = ['‡∏ö‡∏±‡∏ç‡∏ä‡∏µ', '‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£']
    
    # ========== CORE FEATURES (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ö‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö + ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏´‡∏•‡∏±‡∏Å) ==========
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏´‡∏•‡∏±‡∏Å (1-100)
    math_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    computer_score = np.round(np.random.uniform(30, 100, n_samples), 1)  
    language_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    science_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    art_score = np.round(np.random.uniform(30, 100, n_samples), 1)
    
    # ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏´‡∏•‡∏±‡∏Å (1-10 scale)
    logical_thinking = np.round(np.random.uniform(3, 10, n_samples), 1)
    creativity_skill = np.round(np.random.uniform(3, 10, n_samples), 1)
    problem_solving = np.round(np.random.uniform(3, 10, n_samples), 1)
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å (1-10 scale)
    interest_numbers = np.round(np.random.uniform(1, 10, n_samples), 1)
    interest_technology = np.round(np.random.uniform(1, 10, n_samples), 1)
    interest_cooking = np.round(np.random.uniform(1, 10, n_samples), 1)
    
    # ========== DEMOGRAPHIC FEATURES (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ - ‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏¢) ==========
    age = np.random.randint(16, 20, n_samples)
    gender = np.random.choice([0, 1], n_samples)  # 0: ‡∏ä‡∏≤‡∏¢, 1: ‡∏´‡∏ç‡∏¥‡∏á
    family_income = np.random.choice([1, 2, 3, 4, 5], n_samples)  # 1=‡∏ï‡πà‡∏≥, 5=‡∏™‡∏π‡∏á
    parent_education = np.random.choice([1, 2, 3, 4], n_samples)  # 1=‡∏õ‡∏£‡∏∞‡∏ñ‡∏°, 4=‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ+
    siblings_count = np.random.randint(0, 4, n_samples)  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á
    
    # ========== LIFESTYLE FEATURES (‡∏ß‡∏¥‡∏ñ‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï - ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏°‡∏≤‡∏Å) ==========
    sleep_hours = np.round(np.random.uniform(5, 10, n_samples), 1)  # ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ô‡∏≠‡∏ô
    exercise_frequency = np.random.randint(0, 7, n_samples)  # ‡∏ß‡∏±‡∏ô‡∏ï‡πà‡∏≠‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå
    social_media_hours = np.round(np.random.uniform(0, 8, n_samples), 1)  # ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô
    reading_hobby = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])  # ‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
    music_preference = np.random.choice([1, 2, 3, 4], n_samples)  # 1=Pop, 2=Rock, 3=Classical, 4=Country
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
    data = {
        # === CORE FEATURES (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á) ===
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå': math_score,
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå': computer_score,
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢': language_score,
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå': science_score,
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏®‡∏¥‡∏•‡∏õ‡∏∞': art_score,
        '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞': logical_thinking,
        '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå': creativity_skill,
        '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤': problem_solving,
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç': interest_numbers,
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ': interest_technology,
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£': interest_cooking,
        
        # === DEMOGRAPHIC FEATURES (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á) ===
        '‡∏≠‡∏≤‡∏¢‡∏∏': age,
        '‡πÄ‡∏û‡∏®': gender,
        '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß': family_income,
        '‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á': parent_education,
        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á': siblings_count,
        
        # === LIFESTYLE FEATURES (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ô‡πâ‡∏≠‡∏¢) ===
        '‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≠‡∏ô': sleep_hours,
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢': exercise_frequency,
        '‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•‡∏°‡∏µ‡πÄ‡∏î‡∏µ‡∏¢': social_media_hours,
        '‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠': reading_hobby,
        '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö': music_preference,
    }
    
    df = pd.DataFrame(data)
    
    # ========== ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ CORE FEATURES) ==========
    
    # 1. ‡πÅ‡∏ú‡∏ô‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ - ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï + ‡∏ï‡∏£‡∏£‡∏Å‡∏∞ + ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    accounting_score = (
        1.5 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå'] + 
        1.2 * df['‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞'] + 
        1.0 * df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç'] +
        0.5 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢']  # ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£
    )
    
    # 2. ‡πÅ‡∏ú‡∏ô‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏® - ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå + ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ + ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤  
    it_score = (
        1.5 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå'] +
        1.3 * df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ'] +
        1.0 * df['‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤'] +
        0.8 * df['‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞'] +
        0.5 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']
    )
    
    # 3. ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≠‡∏≤‡∏´‡∏≤‡∏£ - ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå + ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£ + ‡∏®‡∏¥‡∏•‡∏õ‡∏∞
    food_score = (
        1.5 * df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£'] +
        1.3 * df['‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå'] +
        1.0 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏®‡∏¥‡∏•‡∏õ‡∏∞'] +
        0.7 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå'] +  # ‡πÄ‡∏Ñ‡∏°‡∏µ‡∏≠‡∏≤‡∏´‡∏≤‡∏£
        0.5 * df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢']  # ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£
    )
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á
    noise_strength = (1.0 - base_accuracy) * 15
    accounting_score += np.random.normal(0, noise_strength, n_samples)
    it_score += np.random.normal(0, noise_strength, n_samples)
    food_score += np.random.normal(0, noise_strength, n_samples)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏ú‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    scores = pd.DataFrame({
        '‡∏ö‡∏±‡∏ç‡∏ä‡∏µ': accounting_score,
        '‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®': it_score,
        '‡∏≠‡∏≤‡∏´‡∏≤‡∏£': food_score
    })
    
    department = scores.idxmax(axis=1)
    df['‡πÅ‡∏ú‡∏ô‡∏Å'] = department
    
    # ========== ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡πÑ‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Validation) ==========
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ (‡∏õ‡∏ß‡∏ä.1-3)
    study_year = np.random.choice([1, 2, 3], n_samples, p=[0.4, 0.35, 0.25])
    df['‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ'] = study_year
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á GPA ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏ú‡∏ô‡∏Å
    max_scores = scores.max(axis=1)
    second_max_scores = scores.apply(lambda x: x.nlargest(2).iloc[1], axis=1)
    decision_margin = max_scores - second_max_scores
    
    base_gpa = 2.5 + (decision_margin / decision_margin.max()) * 1.5
    year_effect = (4 - study_year) * 0.1
    random_noise = np.random.normal(0, 0.3, n_samples)
    
    gpa = np.clip(base_gpa + year_effect + random_noise, 1.0, 4.0)
    gpa = np.round(gpa, 2)
    df['GPA'] = gpa
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à
    satisfaction_base = 3.0
    satisfaction_from_gpa = (gpa - 2.5) * 0.8
    satisfaction_from_margin = (decision_margin / decision_margin.max()) * 1.5
    random_satisfaction_noise = np.random.normal(0, 0.4, n_samples)
    
    satisfaction = satisfaction_base + satisfaction_from_gpa + satisfaction_from_margin + random_satisfaction_noise
    satisfaction = np.clip(satisfaction, 1, 5)
    satisfaction = np.round(satisfaction)
    df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å'] = satisfaction.astype(int)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö "‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏´‡∏°"
    probability_same_choice = (satisfaction - 1) / 4 * 0.7 + (gpa - 1) / 3 * 0.3
    choice_prob = np.random.random(n_samples)
    choice_again = np.where(choice_prob < probability_same_choice, 
                           np.random.choice([1, 2], n_samples, p=[0.6, 0.4]),
                           np.random.choice([3, 4, 5], n_samples, p=[0.3, 0.4, 0.3]))
    
    df['‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏´‡∏°'] = choice_again
    
    # ========== ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ==========
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    core_features = [
        '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏®‡∏¥‡∏•‡∏õ‡∏∞',
        '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞', '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå', '‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤',
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£'
    ]
    
    demographic_features = [
        '‡∏≠‡∏≤‡∏¢‡∏∏', '‡πÄ‡∏û‡∏®', '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß', '‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á'
    ]
    
    lifestyle_features = [
        '‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≠‡∏ô', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢', '‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•‡∏°‡∏µ‡πÄ‡∏î‡∏µ‡∏¢', '‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠', '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö'
    ]
    
    X = df.drop('‡πÅ‡∏ú‡∏ô‡∏Å', axis=1)
    y = df['‡πÅ‡∏ú‡∏ô‡∏Å']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    model_all = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=seed)
    model_all.fit(X_train, y_train)
    y_pred_all = model_all.predict(X_test)
    accuracy_all = accuracy_score(y_test, y_pred_all)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö core features ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    X_core = df[core_features]
    X_train_core, X_test_core, _, _ = train_test_split(X_core, y, test_size=0.3, random_state=seed, stratify=y)
    
    model_core = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=seed)
    model_core.fit(X_train_core, y_train)
    y_pred_core = model_core.predict(X_test_core)
    accuracy_core = accuracy_score(y_test, y_pred_core)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô {n_samples} ‡∏Ñ‡∏ô")
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏Å:")
    print(df['‡πÅ‡∏ú‡∏ô‡∏Å'].value_counts())
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ:")
    print(df['‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ'].value_counts())
    
    print(f"\nüìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
    print(f"üîç ‡πÉ‡∏ä‡πâ Features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({len(X.columns)} features): {accuracy_all:.3f}")
    print(f"üéØ ‡πÉ‡∏ä‡πâ Core Features ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ({len(core_features)} features): {accuracy_core:.3f}")
    print(f"‚ú® ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: {accuracy_core - accuracy_all:.3f}")
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå GPA ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à
    print(f"\nüìà ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå GPA:")
    print(f"üìä GPA ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {df['GPA'].mean():.2f} (SD: {df['GPA'].std():.2f})")
    
    high_gpa = df[df['GPA'] >= 3.5]
    mid_gpa = df[(df['GPA'] >= 2.5) & (df['GPA'] < 3.5)]
    low_gpa = df[df['GPA'] < 2.5]
    
    print(f"üü¢ GPA ‡∏™‡∏π‡∏á (‚â•3.5): {len(high_gpa)} ‡∏Ñ‡∏ô ({len(high_gpa)/len(df)*100:.1f}%)")
    print(f"üü° GPA ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á (2.5-3.5): {len(mid_gpa)} ‡∏Ñ‡∏ô ({len(mid_gpa)/len(df)*100:.1f}%)")
    print(f"üî¥ GPA ‡∏ï‡πà‡∏≥ (<2.5): {len(low_gpa)} ‡∏Ñ‡∏ô ({len(low_gpa)/len(df)*100:.1f}%)")
    
    print(f"\nüòä ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à:")
    satisfaction_counts = df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å'].value_counts().sort_index()
    for score, count in satisfaction_counts.items():
        emoji = ['üò°', 'üòû', 'üòê', 'üòä', 'üòç'][score-1]
        print(f"{emoji} ‡∏£‡∏∞‡∏î‡∏±‡∏ö {score}: {count} ‡∏Ñ‡∏ô ({count/len(df)*100:.1f}%)")
    
    print(f"\nüîÑ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå '‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà':")
    choice_labels = ['‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô', '‡∏≠‡∏≤‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏¥‡∏°', '‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à', '‡∏≠‡∏≤‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô', '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô']
    choice_counts = df['‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏´‡∏°'].value_counts().sort_index()
    for choice, count in choice_counts.items():
        print(f"  {choice}. {choice_labels[choice-1]}: {count} ‡∏Ñ‡∏ô ({count/len(df)*100:.1f}%)")
    
    print(f"\nüìã ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏£‡∏∏‡∏õ:")
    print(f"üéØ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {df['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å'].mean():.2f}/5")
    print(f"üîÑ % ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏° (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 1-2): {((df['‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏´‡∏°'] <= 2).sum() / len(df) * 100):.1f}%")
    print(f"üíî % ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡∏≠‡∏∑‡πà‡∏ô (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 4-5): {((df['‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏´‡∏°'] >= 4).sum() / len(df) * 100):.1f}%")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á features
    feature_imp_all = None
    feature_imp_core = None
    
    if hasattr(model_all, 'feature_importances_'):
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó features
        feature_types = []
        for feature in X.columns:
            if feature in core_features:
                feature_types.append('Core')
            elif feature in demographic_features:
                feature_types.append('Demographic')  
            elif feature in lifestyle_features:
                feature_types.append('Lifestyle')
            else:
                feature_types.append('Additional')
        
        feature_imp_all = pd.DataFrame({
            'Feature': X.columns,
            'Importance': model_all.feature_importances_,
            'Type': feature_types
        }).sort_values('Importance', ascending=False)
        
        feature_imp_core = pd.DataFrame({
            'Feature': core_features,
            'Importance': model_core.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        print("\nüèÜ Top 10 Most Important Features (All):")
        print(feature_imp_all.head(10)[['Feature', 'Importance', 'Type']])
        
        print("\nüéØ Core Features Importance:")
        print(feature_imp_core.head())
    
    return df, accuracy_all, accuracy_core, feature_imp_all, feature_imp_core, core_features, demographic_features, lifestyle_features

if __name__ == "__main__":
    print("=== ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á ===")
    
    df, acc_all, acc_core, feat_imp_all, feat_imp_core, core_feat, demo_feat, life_feat = generate_realistic_student_dataset(
        n_samples=2000,
        base_accuracy=0.80,
        target_after_selection=0.87,
        seed=42
    )
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    df.to_csv('student_realistic_data.csv', index=False, encoding='utf-8-sig')
    print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå student_realistic_data.csv ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
    print(f"üìù Total Features: {len(df.columns)-1}")
    print(f"üìä Total Rows: {len(df)}")